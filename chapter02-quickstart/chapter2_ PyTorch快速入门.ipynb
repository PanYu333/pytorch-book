{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 PyTorch第一步\n",
    "\n",
    "PyTorch的简洁设计使得它入门很简单，在深入介绍PyTorch之前，本节将先介绍一些PyTorch的基础知识，使得读者能够对PyTorch有一个大致的了解，并能够用PyTorch搭建一个简单的神经网络。部分内容读者可能暂时不太理解，可先不予以深究，本书的第3章和第4章将会对此进行深入讲解。\n",
    "\n",
    "本节内容参考了PyTorch官方教程[^1]并做了相应的增删修改，使得内容更贴合新版本的PyTorch接口，同时也更适合新手快速入门。另外本书需要读者先掌握基础的Numpy使用，其他相关知识推荐读者参考CS231n的教程[^2]。\n",
    "\n",
    "[^1]: http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
    "[^2]: http://cs231n.github.io/python-numpy-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor\n",
    "\n",
    "Tensor是PyTorch中重要的数据结构，可认为是一个高维数组。它可以是一个数（标量）、一维数组（向量）、二维数组（矩阵）以及更高维的数组。Tensor和Numpy的ndarrays类似，但Tensor可以使用GPU进行加速。Tensor的使用和Numpy及Matlab的接口十分相似，下面通过几个例子来看看Tensor的基本使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1+cu116'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch as t\n",
    "t.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建 5x3 矩阵，只是分配了空间，未初始化\n",
    "x = t.Tensor(5, 3)\n",
    "\n",
    "x = t.Tensor([[1,2],[3,4]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7839, 0.5761, 0.0867],\n",
       "        [0.5444, 0.1567, 0.2950],\n",
       "        [0.4937, 0.8178, 0.4766],\n",
       "        [0.0456, 0.7029, 0.6736],\n",
       "        [0.1228, 0.5421, 0.8524]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用[0,1]均匀分布随机初始化二维数组\n",
    "x = t.rand(5, 3)  \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.size()) # 查看x的形状\n",
    "x.size()[1], x.size(1) # 查看列的个数, 两种写法等价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.Size` 是tuple对象的子类，因此它支持tuple的所有操作，如x.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0392, 0.6343, 0.5908],\n",
       "        [0.9393, 1.1014, 0.9635],\n",
       "        [1.1813, 1.2687, 1.4713],\n",
       "        [0.3805, 1.1191, 1.3376],\n",
       "        [0.2820, 0.5629, 1.6833]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = t.rand(5, 3)\n",
    "# 加法的第一种写法\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0392, 0.6343, 0.5908],\n",
       "        [0.9393, 1.1014, 0.9635],\n",
       "        [1.1813, 1.2687, 1.4713],\n",
       "        [0.3805, 1.1191, 1.3376],\n",
       "        [0.2820, 0.5629, 1.6833]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加法的第二种写法\n",
    "t.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0392, 0.6343, 0.5908],\n",
       "        [0.9393, 1.1014, 0.9635],\n",
       "        [1.1813, 1.2687, 1.4713],\n",
       "        [0.3805, 1.1191, 1.3376],\n",
       "        [0.2820, 0.5629, 1.6833]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加法的第三种写法：指定加法结果的输出目标为result\n",
    "result = t.Tensor(5, 3) # 预先分配空间\n",
    "t.add(x, y, out=result) # 输入到result\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最初y\n",
      "tensor([[0.2552, 0.0582, 0.5041],\n",
      "        [0.3949, 0.9447, 0.6685],\n",
      "        [0.6876, 0.4509, 0.9947],\n",
      "        [0.3349, 0.4162, 0.6639],\n",
      "        [0.1592, 0.0209, 0.8309]])\n",
      "第一种加法，y的结果\n",
      "tensor([[0.2552, 0.0582, 0.5041],\n",
      "        [0.3949, 0.9447, 0.6685],\n",
      "        [0.6876, 0.4509, 0.9947],\n",
      "        [0.3349, 0.4162, 0.6639],\n",
      "        [0.1592, 0.0209, 0.8309]])\n",
      "第二种加法，y的结果\n",
      "tensor([[1.0392, 0.6343, 0.5908],\n",
      "        [0.9393, 1.1014, 0.9635],\n",
      "        [1.1813, 1.2687, 1.4713],\n",
      "        [0.3805, 1.1191, 1.3376],\n",
      "        [0.2820, 0.5629, 1.6833]])\n"
     ]
    }
   ],
   "source": [
    "print('最初y')\n",
    "print(y)\n",
    "\n",
    "print('第一种加法，y的结果')\n",
    "y.add(x) # 普通加法，不改变y的内容\n",
    "print(y)\n",
    "\n",
    "print('第二种加法，y的结果')\n",
    "y.add_(x) # inplace 加法，y变了\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，函数名后面带下划线**`_`** 的函数会修改Tensor本身。例如，`x.add_(y)`和`x.t_()`会改变 `x`，但`x.add(y)`和`x.t()`返回一个新的Tensor， 而`x`不变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5761, 0.1567, 0.8178, 0.7029, 0.5421])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor的选取操作与Numpy类似\n",
    "x[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor还支持很多操作，包括数学运算、线性代数、选择、切片等等，其接口设计与Numpy极为相似。更详细的使用方法，会在第三章系统讲解。\n",
    "\n",
    "Tensor和Numpy的数组之间的互操作非常容易且快速。对于Tensor不支持的操作，可以先转为Numpy数组处理，之后再转回Tensor。c\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.ones(5) # 新建一个全1的Tensor\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.numpy() # Tensor -> Numpy\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = t.from_numpy(a) # Numpy->Tensor\n",
    "print(a)\n",
    "print(b) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor和numpy对象共享内存，所以他们之间的转换很快，而且几乎不会消耗什么资源。但这也意味着，如果其中一个变了，另外一个也会随之改变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "b.add_(1) # 以`_`结尾的函数会修改自身\n",
    "print(a)\n",
    "print(b) # Tensor和Numpy共享内存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想获取某一个元素的值，可以使用`scalar.item`。 直接`tensor[idx]`得到的还是一个tensor: 一个0-dim 的tensor，一般称为scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = b[0]\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.size() #0-dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item() # 使用scalar.item()能从中取出python对象的数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2]), tensor(2., dtype=torch.float64))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = t.tensor([2]) # 注意和scalar的区别\n",
    "tensor,scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1]), torch.Size([]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.size(),scalar.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 只有一个元素的tensor也可以调用`tensor.item()`\n",
    "tensor.item(), scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外在pytorch中还有一个和`np.array` 很类似的接口: `torch.tensor`, 二者的使用十分类似。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = t.tensor([3,4]) # 新建一个包含 3，4 两个元素的tensor\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = t.tensor(3)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 4]), tensor([1111,    4]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_tensor = tensor\n",
    "new_tensor = old_tensor.clone()\n",
    "new_tensor[0] = 1111\n",
    "old_tensor, new_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是，`t.tensor()`或者`tensor.clone()`总是会进行数据拷贝，新tensor和原来的数据不再共享内存。所以如果你想共享内存的话，建议使用`torch.from_numpy()`或者`tensor.detach()`来新建一个tensor, 二者共享内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1111,    4]), tensor([1111,    4]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor = old_tensor.detach()\n",
    "new_tensor[0] = 1111\n",
    "old_tensor, new_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor可通过`.cuda` 方法转为GPU的Tensor，从而享受GPU带来的加速运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 在不支持CUDA的机器下，下一步还是在CPU上运行\n",
    "device = t.device(\"cuda:0\" if t.cuda.is_available() else \"cpu\")\n",
    "x = x.to(device)\n",
    "y = y.to(x.device)\n",
    "z = x+y\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外，还可以使用`tensor.cuda()` 的方式将tensor拷贝到gpu上，但是这种方式不太推荐。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处可能发现GPU运算的速度并未提升太多，这是因为x和y太小且运算也较为简单，而且将数据从内存转移到显存还需要花费额外的开销。GPU的优势需在大规模数据和复杂运算下才能体现出来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### autograd: 自动微分\n",
    "\n",
    "深度学习的算法本质上是通过反向传播求导数，而PyTorch的**`autograd`**模块则实现了此功能。在Tensor上的所有操作，autograd都能为它们自动提供微分，避免了手动计算导数的复杂过程。\n",
    " \n",
    "~~`autograd.Variable`是Autograd中的核心类，它简单封装了Tensor，并支持几乎所有Tensor有的操作。Tensor在被封装为Variable之后，可以调用它的`.backward`实现反向传播，自动计算所有梯度~~ ~~Variable的数据结构如图2-6所示。~~\n",
    "\n",
    "\n",
    "![图2-6:Variable的数据结构](imgs/autograd_Variable.svg)\n",
    "\n",
    "  *从0.4起, Variable 正式合并入Tensor, Variable 本来实现的自动微分功能，Tensor就能支持。读者还是可以使用Variable(tensor), 但是这个操作其实什么都没做。建议读者以后直接使用tensor*. \n",
    "  \n",
    "  要想使得Tensor使用autograd功能，只需要设置`tensor.requries_grad=True`. \n",
    "\n",
    "\n",
    "~~Variable主要包含三个属性。~~\n",
    "~~- `data`：保存Variable所包含的Tensor~~\n",
    "~~- `grad`：保存`data`对应的梯度，`grad`也是个Variable，而不是Tensor，它和`data`的形状一样。~~\n",
    "~~- `grad_fn`：指向一个`Function`对象，这个`Function`用来反向传播计算输入的梯度，具体细节会在下一章讲解。~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 为tensor设置 requires_grad 标识，代表着需要求导数\n",
    "# pytorch 会自动调用autograd 记录操作\n",
    "x = t.ones(2, 2, requires_grad=True)\n",
    "\n",
    "# 上一步等价于\n",
    "# x = t.ones(2,2)\n",
    "# x.requires_grad = True\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.sum()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SumBackward0 at 0x1d5256d5c70>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward() # 反向传播,计算梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = x.sum() = (x[0][0] + x[0][1] + x[1][0] + x[1][1])\n",
    "# 每个值的梯度都为1\n",
    "x.grad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：`grad`在反向传播过程中是累加的(accumulated)，这意味着每一次运行反向传播，梯度都会累加之前的梯度，所以反向传播之前需把梯度清零。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [2., 2.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [3., 3.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以下划线结束的函数是inplace操作，会修改自身的值，就像add_\n",
    "x.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  神经网络\n",
    "\n",
    "Autograd实现了反向传播功能，但是直接用来写深度学习的代码在很多情况下还是稍显复杂，torch.nn是专门为神经网络设计的模块化接口。nn构建于 Autograd之上，可用来定义和运行神经网络。nn.Module是nn中最重要的类，可把它看成是一个网络的封装，包含网络各层定义以及forward方法，调用forward(input)方法，可返回前向传播的结果。下面就以最早的卷积神经网络：LeNet为例，来看看如何用`nn.Module`实现。LeNet的网络结构如图2-7所示。\n",
    "\n",
    "![图2-7:LeNet网络结构](imgs/nn_lenet.png)\n",
    "\n",
    "这是一个基础的前向传播(feed-forward)网络: 接收输入，经过层层传递运算，得到输出。\n",
    "\n",
    "#### 定义网络\n",
    "\n",
    "定义网络时，需要继承`nn.Module`，并实现它的forward方法，把网络中具有可学习参数的层放在构造函数`__init__`中。如果某一层(如ReLU)不具有可学习的参数，则既可以放在构造函数中，也可以不放，但建议不放在其中，而在forward中使用`nn.functional`代替。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        # nn.Module子类的函数必须在构造函数中执行父类的构造函数\n",
    "        # 下式等价于nn.Module.__init__(self)\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # 卷积层 '1'表示输入图片为单通道, '6'表示输出通道数，'5'表示卷积核为5*5\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)      \n",
    "        # 卷积层\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) \n",
    "        # 仿射层/全连接层，y = Wx + b\n",
    "        self.fc1   = nn.Linear(16*5*5, 120) \n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x): \n",
    "        # 卷积 -> 激活 -> 池化 \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) \n",
    "        # reshape，‘-1’表示自适应\n",
    "        x = x.view(x.size()[0], -1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)        \n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只要在nn.Module的子类中定义了forward函数，backward函数就会自动被实现(利用`autograd`)。在`forward` 函数中可使用任何tensor支持的函数，还可以使用if、for循环、print、log等Python语法，写法和标准的Python写法一致。\n",
    "\n",
    "网络的可学习参数通过`net.parameters()`返回，`net.named_parameters`可同时返回可学习的参数及名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[-1.3900e-01, -1.2511e-01, -1.3530e-01,  1.0219e-01,  3.0436e-02],\n",
      "          [ 6.3789e-04,  4.0715e-02, -1.7053e-01,  8.2959e-02,  1.9595e-01],\n",
      "          [ 7.7062e-02, -1.5350e-02,  1.4892e-01,  1.3372e-01, -4.1485e-05],\n",
      "          [-1.6007e-01,  9.9656e-02, -1.7958e-01, -2.2921e-02, -1.2304e-01],\n",
      "          [ 1.2122e-02, -8.9118e-02, -3.1090e-02,  1.5458e-01,  1.6814e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8430e-01, -7.6897e-02, -1.0660e-01, -8.9521e-02,  1.5412e-01],\n",
      "          [-1.7514e-01, -1.6359e-01,  9.6623e-02,  9.5441e-02, -1.9282e-02],\n",
      "          [-1.1623e-01,  6.7653e-02, -1.1192e-01,  1.4316e-01, -4.9145e-02],\n",
      "          [-3.5377e-02,  1.7992e-01, -2.8595e-02, -1.6519e-01, -6.0853e-03],\n",
      "          [-1.4646e-01, -1.7410e-01,  1.3802e-01,  4.5829e-04,  1.2928e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0174e-01,  3.3341e-02,  1.1726e-01, -2.4656e-02,  1.7391e-01],\n",
      "          [ 4.4220e-02,  6.1958e-02, -1.0664e-01, -1.0041e-01, -8.2737e-02],\n",
      "          [-9.2420e-03,  1.3439e-01, -1.9770e-01, -1.3730e-01,  1.7358e-01],\n",
      "          [ 2.6758e-02,  6.9531e-02,  1.4861e-01, -4.7092e-02,  4.1074e-02],\n",
      "          [ 1.3926e-01, -6.7846e-02,  1.6522e-01,  1.2706e-01,  2.5429e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.9286e-01, -7.5132e-02,  1.7656e-01,  1.1083e-02, -1.9218e-01],\n",
      "          [ 5.1195e-02,  1.3889e-01,  1.4183e-01,  8.4849e-02, -1.6641e-01],\n",
      "          [ 1.1792e-01, -5.0843e-02, -9.6349e-02,  1.0227e-01,  7.0769e-02],\n",
      "          [ 1.5232e-01,  2.3563e-02, -7.6552e-02,  1.7800e-02, -1.9020e-01],\n",
      "          [-1.5430e-01,  1.0516e-01,  3.4099e-02,  1.8555e-01, -1.9786e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5619e-02, -2.9904e-02, -1.0646e-01,  1.2698e-01,  4.9605e-02],\n",
      "          [-2.7741e-03, -9.2480e-02, -2.8858e-02,  1.7856e-01,  4.1469e-02],\n",
      "          [ 1.9232e-01, -2.9301e-02, -8.9988e-02,  1.1869e-01,  5.8548e-02],\n",
      "          [ 5.0249e-02, -1.0191e-01,  7.7690e-02,  1.3961e-01, -4.3559e-02],\n",
      "          [-8.3619e-02,  6.2289e-02, -1.4997e-01, -3.6102e-02,  5.3619e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2032e-01, -3.9008e-02, -1.5125e-01, -1.7474e-01, -1.9012e-01],\n",
      "          [-1.6721e-01,  5.5491e-02, -1.6659e-01, -1.4361e-01, -4.7986e-02],\n",
      "          [-6.4867e-02, -1.8016e-02,  1.8060e-01, -1.0868e-01, -2.2711e-03],\n",
      "          [ 1.6549e-01,  1.9982e-01, -9.4364e-02,  6.2897e-02, -1.4151e-01],\n",
      "          [-5.0605e-02,  2.2615e-02,  1.1645e-01,  1.6998e-01, -1.5496e-01]]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.1404, -0.1385,  0.0273,  0.0239,  0.0675, -0.1544],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 0.0084,  0.0024,  0.0540, -0.0146, -0.0791],\n",
      "          [-0.0648, -0.0744,  0.0805,  0.0774, -0.0187],\n",
      "          [ 0.0613,  0.0248, -0.0471,  0.0203,  0.0657],\n",
      "          [-0.0240,  0.0327, -0.0404, -0.0705,  0.0150],\n",
      "          [-0.0792, -0.0294, -0.0770, -0.0196, -0.0326]],\n",
      "\n",
      "         [[ 0.0332,  0.0359,  0.0658, -0.0608,  0.0763],\n",
      "          [-0.0517,  0.0158, -0.0257,  0.0810,  0.0467],\n",
      "          [-0.0052, -0.0705,  0.0258, -0.0290, -0.0493],\n",
      "          [ 0.0225,  0.0776, -0.0173, -0.0270, -0.0273],\n",
      "          [ 0.0032, -0.0278, -0.0081, -0.0646,  0.0307]],\n",
      "\n",
      "         [[-0.0418,  0.0041, -0.0800, -0.0513, -0.0449],\n",
      "          [ 0.0630,  0.0771, -0.0617, -0.0306, -0.0289],\n",
      "          [-0.0712,  0.0584, -0.0770, -0.0764,  0.0776],\n",
      "          [-0.0519, -0.0550,  0.0672, -0.0273, -0.0478],\n",
      "          [ 0.0749,  0.0221,  0.0090, -0.0218, -0.0697]],\n",
      "\n",
      "         [[ 0.0202,  0.0775,  0.0649, -0.0772, -0.0098],\n",
      "          [ 0.0369,  0.0722, -0.0039, -0.0354,  0.0254],\n",
      "          [-0.0608, -0.0728, -0.0206,  0.0811, -0.0571],\n",
      "          [-0.0798,  0.0606, -0.0695, -0.0416,  0.0643],\n",
      "          [ 0.0311,  0.0014, -0.0010,  0.0140,  0.0691]],\n",
      "\n",
      "         [[ 0.0448, -0.0381,  0.0090,  0.0633, -0.0084],\n",
      "          [-0.0508, -0.0788, -0.0650,  0.0390,  0.0326],\n",
      "          [-0.0227,  0.0529, -0.0453,  0.0800, -0.0767],\n",
      "          [-0.0421,  0.0076, -0.0509, -0.0400, -0.0431],\n",
      "          [-0.0630, -0.0635, -0.0350, -0.0031,  0.0105]],\n",
      "\n",
      "         [[-0.0729,  0.0054,  0.0194, -0.0420, -0.0247],\n",
      "          [ 0.0553,  0.0355,  0.0187, -0.0777,  0.0030],\n",
      "          [-0.0547, -0.0419,  0.0415,  0.0713, -0.0357],\n",
      "          [ 0.0277, -0.0518,  0.0046,  0.0598,  0.0683],\n",
      "          [ 0.0570,  0.0746, -0.0693, -0.0587, -0.0634]]],\n",
      "\n",
      "\n",
      "        [[[-0.0735, -0.0238,  0.0353, -0.0064, -0.0562],\n",
      "          [ 0.0621,  0.0069,  0.0585,  0.0030,  0.0340],\n",
      "          [ 0.0474, -0.0664,  0.0624, -0.0407, -0.0204],\n",
      "          [ 0.0262, -0.0464,  0.0521, -0.0500, -0.0763],\n",
      "          [ 0.0115, -0.0749,  0.0088,  0.0274,  0.0693]],\n",
      "\n",
      "         [[ 0.0023,  0.0645, -0.0771, -0.0190, -0.0512],\n",
      "          [-0.0002, -0.0014,  0.0034, -0.0215, -0.0014],\n",
      "          [-0.0395, -0.0808,  0.0062, -0.0443,  0.0233],\n",
      "          [ 0.0324, -0.0197,  0.0496,  0.0629, -0.0674],\n",
      "          [ 0.0767,  0.0496, -0.0416, -0.0343,  0.0140]],\n",
      "\n",
      "         [[-0.0042,  0.0514, -0.0753,  0.0453,  0.0613],\n",
      "          [-0.0114, -0.0430, -0.0552, -0.0072,  0.0022],\n",
      "          [-0.0454, -0.0082,  0.0460,  0.0563,  0.0280],\n",
      "          [-0.0115,  0.0664, -0.0211,  0.0384,  0.0225],\n",
      "          [ 0.0624,  0.0127, -0.0549, -0.0645,  0.0208]],\n",
      "\n",
      "         [[ 0.0360,  0.0615,  0.0689, -0.0276, -0.0630],\n",
      "          [-0.0072,  0.0254,  0.0475,  0.0207,  0.0497],\n",
      "          [ 0.0364,  0.0532, -0.0317, -0.0632, -0.0163],\n",
      "          [ 0.0642,  0.0233,  0.0529, -0.0102,  0.0108],\n",
      "          [ 0.0084,  0.0213,  0.0435, -0.0145,  0.0188]],\n",
      "\n",
      "         [[-0.0506,  0.0057,  0.0428, -0.0565,  0.0053],\n",
      "          [ 0.0447,  0.0343, -0.0815, -0.0191, -0.0014],\n",
      "          [-0.0055,  0.0525,  0.0588, -0.0143,  0.0076],\n",
      "          [ 0.0188, -0.0288, -0.0180,  0.0591,  0.0187],\n",
      "          [ 0.0166, -0.0292,  0.0556, -0.0152, -0.0353]],\n",
      "\n",
      "         [[ 0.0111, -0.0027,  0.0127, -0.0646,  0.0062],\n",
      "          [-0.0476,  0.0678, -0.0069,  0.0411,  0.0697],\n",
      "          [ 0.0215, -0.0171, -0.0206, -0.0322,  0.0133],\n",
      "          [-0.0473,  0.0738,  0.0328,  0.0434, -0.0087],\n",
      "          [ 0.0549,  0.0602, -0.0091,  0.0674,  0.0732]]],\n",
      "\n",
      "\n",
      "        [[[-0.0152,  0.0626, -0.0486,  0.0419,  0.0340],\n",
      "          [-0.0767,  0.0652, -0.0133,  0.0775,  0.0022],\n",
      "          [ 0.0089, -0.0397,  0.0640, -0.0401,  0.0548],\n",
      "          [-0.0078, -0.0247,  0.0808,  0.0337, -0.0147],\n",
      "          [ 0.0302, -0.0622,  0.0426,  0.0072,  0.0084]],\n",
      "\n",
      "         [[ 0.0630, -0.0547,  0.0742,  0.0567, -0.0659],\n",
      "          [ 0.0179,  0.0383, -0.0083, -0.0142,  0.0613],\n",
      "          [-0.0568, -0.0473,  0.0346,  0.0341,  0.0189],\n",
      "          [ 0.0295,  0.0177,  0.0324, -0.0297, -0.0530],\n",
      "          [ 0.0725,  0.0327,  0.0007, -0.0210, -0.0707]],\n",
      "\n",
      "         [[-0.0729,  0.0175, -0.0520,  0.0445, -0.0125],\n",
      "          [ 0.0257,  0.0559, -0.0301,  0.0109,  0.0499],\n",
      "          [ 0.0485, -0.0130,  0.0366,  0.0140,  0.0544],\n",
      "          [-0.0115, -0.0668,  0.0225, -0.0267,  0.0289],\n",
      "          [-0.0080, -0.0038, -0.0481, -0.0107, -0.0051]],\n",
      "\n",
      "         [[ 0.0094, -0.0277,  0.0396, -0.0693, -0.0366],\n",
      "          [ 0.0077,  0.0271, -0.0521, -0.0517, -0.0735],\n",
      "          [ 0.0706, -0.0065, -0.0450,  0.0693,  0.0377],\n",
      "          [ 0.0801,  0.0417,  0.0198,  0.0031,  0.0347],\n",
      "          [ 0.0781, -0.0014, -0.0139, -0.0146, -0.0148]],\n",
      "\n",
      "         [[ 0.0393,  0.0487,  0.0471,  0.0021, -0.0688],\n",
      "          [ 0.0342,  0.0280,  0.0684, -0.0564,  0.0250],\n",
      "          [ 0.0375,  0.0808,  0.0179, -0.0568,  0.0666],\n",
      "          [-0.0184, -0.0504, -0.0581,  0.0297, -0.0718],\n",
      "          [ 0.0004, -0.0581, -0.0259,  0.0657,  0.0061]],\n",
      "\n",
      "         [[ 0.0499, -0.0530, -0.0752, -0.0401,  0.0475],\n",
      "          [ 0.0539, -0.0535, -0.0516, -0.0126, -0.0179],\n",
      "          [ 0.0144, -0.0665,  0.0064,  0.0328,  0.0420],\n",
      "          [-0.0680, -0.0232, -0.0520, -0.0685, -0.0749],\n",
      "          [-0.0602, -0.0732,  0.0042, -0.0784, -0.0170]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0220, -0.0291,  0.0743, -0.0288,  0.0017],\n",
      "          [-0.0516,  0.0227, -0.0154, -0.0304, -0.0078],\n",
      "          [ 0.0472, -0.0567,  0.0760,  0.0442, -0.0669],\n",
      "          [-0.0768, -0.0016,  0.0340,  0.0191,  0.0492],\n",
      "          [ 0.0130, -0.0144,  0.0216, -0.0772,  0.0393]],\n",
      "\n",
      "         [[ 0.0542, -0.0738, -0.0570,  0.0487,  0.0071],\n",
      "          [ 0.0496,  0.0087,  0.0271,  0.0592,  0.0297],\n",
      "          [ 0.0372, -0.0719,  0.0615, -0.0005, -0.0175],\n",
      "          [ 0.0182, -0.0099,  0.0454,  0.0199,  0.0406],\n",
      "          [-0.0531, -0.0280, -0.0101,  0.0278, -0.0433]],\n",
      "\n",
      "         [[ 0.0726,  0.0501, -0.0310, -0.0466,  0.0554],\n",
      "          [ 0.0249,  0.0292,  0.0059,  0.0300, -0.0539],\n",
      "          [-0.0592,  0.0367, -0.0683, -0.0296, -0.0418],\n",
      "          [-0.0578,  0.0403,  0.0387, -0.0304,  0.0323],\n",
      "          [ 0.0816,  0.0809,  0.0724,  0.0372,  0.0131]],\n",
      "\n",
      "         [[-0.0314, -0.0086,  0.0418, -0.0070,  0.0299],\n",
      "          [ 0.0717, -0.0054, -0.0256,  0.0507, -0.0519],\n",
      "          [-0.0083, -0.0702,  0.0408, -0.0693, -0.0539],\n",
      "          [-0.0442,  0.0128,  0.0195,  0.0721,  0.0748],\n",
      "          [-0.0556,  0.0585,  0.0608,  0.0718, -0.0443]],\n",
      "\n",
      "         [[ 0.0072, -0.0468,  0.0303, -0.0426,  0.0265],\n",
      "          [-0.0369,  0.0658, -0.0534, -0.0764, -0.0038],\n",
      "          [ 0.0675, -0.0756, -0.0138,  0.0300,  0.0360],\n",
      "          [-0.0629,  0.0145, -0.0255, -0.0671, -0.0203],\n",
      "          [ 0.0443,  0.0378, -0.0708, -0.0041, -0.0700]],\n",
      "\n",
      "         [[-0.0495,  0.0470, -0.0512,  0.0503, -0.0104],\n",
      "          [-0.0257,  0.0517, -0.0155, -0.0585, -0.0214],\n",
      "          [-0.0204,  0.0679, -0.0147,  0.0331, -0.0524],\n",
      "          [ 0.0785, -0.0738,  0.0602,  0.0736, -0.0117],\n",
      "          [ 0.0669, -0.0424, -0.0563,  0.0297,  0.0153]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0204, -0.0459, -0.0375,  0.0242,  0.0258],\n",
      "          [ 0.0045,  0.0805, -0.0663, -0.0659, -0.0674],\n",
      "          [ 0.0269,  0.0272,  0.0044, -0.0146,  0.0019],\n",
      "          [-0.0797, -0.0688,  0.0296, -0.0068, -0.0509],\n",
      "          [-0.0420,  0.0058, -0.0223,  0.0385, -0.0660]],\n",
      "\n",
      "         [[-0.0263,  0.0108, -0.0377, -0.0073, -0.0547],\n",
      "          [ 0.0328, -0.0408,  0.0430, -0.0069, -0.0358],\n",
      "          [-0.0455, -0.0558, -0.0371, -0.0304,  0.0796],\n",
      "          [-0.0252,  0.0435, -0.0005,  0.0406, -0.0033],\n",
      "          [ 0.0445,  0.0157, -0.0254, -0.0201,  0.0741]],\n",
      "\n",
      "         [[-0.0172, -0.0216,  0.0622, -0.0753, -0.0118],\n",
      "          [-0.0151,  0.0046, -0.0287,  0.0360,  0.0801],\n",
      "          [-0.0344, -0.0102, -0.0466,  0.0763, -0.0671],\n",
      "          [-0.0676, -0.0599, -0.0767, -0.0030,  0.0413],\n",
      "          [ 0.0685, -0.0183, -0.0359,  0.0117,  0.0358]],\n",
      "\n",
      "         [[-0.0479,  0.0261, -0.0800,  0.0585, -0.0658],\n",
      "          [ 0.0786, -0.0300,  0.0323,  0.0738, -0.0153],\n",
      "          [-0.0342,  0.0794,  0.0655, -0.0085, -0.0429],\n",
      "          [ 0.0461,  0.0162, -0.0756,  0.0358, -0.0102],\n",
      "          [ 0.0742, -0.0664,  0.0653,  0.0150, -0.0618]],\n",
      "\n",
      "         [[ 0.0097, -0.0676,  0.0098, -0.0481,  0.0284],\n",
      "          [ 0.0675,  0.0474,  0.0557,  0.0640,  0.0659],\n",
      "          [ 0.0778, -0.0552, -0.0650,  0.0553,  0.0147],\n",
      "          [ 0.0805, -0.0294,  0.0135, -0.0535,  0.0440],\n",
      "          [ 0.0706,  0.0774,  0.0163, -0.0793, -0.0548]],\n",
      "\n",
      "         [[ 0.0802, -0.0800,  0.0088, -0.0225, -0.0048],\n",
      "          [ 0.0164,  0.0386,  0.0220, -0.0716,  0.0792],\n",
      "          [ 0.0207,  0.0041,  0.0555, -0.0686,  0.0424],\n",
      "          [ 0.0179, -0.0489,  0.0185, -0.0589,  0.0544],\n",
      "          [ 0.0207, -0.0757,  0.0724,  0.0529, -0.0407]]],\n",
      "\n",
      "\n",
      "        [[[-0.0521,  0.0078,  0.0675,  0.0331,  0.0283],\n",
      "          [ 0.0073,  0.0474, -0.0060,  0.0310, -0.0139],\n",
      "          [ 0.0169,  0.0778, -0.0442,  0.0115, -0.0603],\n",
      "          [-0.0399,  0.0410,  0.0337, -0.0269,  0.0426],\n",
      "          [-0.0643, -0.0645, -0.0024,  0.0319, -0.0017]],\n",
      "\n",
      "         [[-0.0594,  0.0096,  0.0740,  0.0777, -0.0731],\n",
      "          [-0.0353, -0.0541,  0.0648, -0.0121, -0.0514],\n",
      "          [ 0.0357, -0.0330,  0.0785,  0.0653, -0.0057],\n",
      "          [ 0.0433, -0.0264,  0.0467, -0.0647, -0.0757],\n",
      "          [-0.0541, -0.0354,  0.0683,  0.0480, -0.0816]],\n",
      "\n",
      "         [[-0.0626, -0.0316,  0.0681, -0.0526, -0.0302],\n",
      "          [ 0.0339,  0.0142,  0.0218,  0.0593, -0.0013],\n",
      "          [ 0.0672,  0.0264, -0.0791, -0.0568,  0.0548],\n",
      "          [ 0.0513, -0.0183,  0.0480, -0.0555, -0.0808],\n",
      "          [-0.0005, -0.0060, -0.0674, -0.0177, -0.0537]],\n",
      "\n",
      "         [[-0.0408,  0.0233,  0.0204,  0.0632, -0.0246],\n",
      "          [ 0.0403,  0.0609, -0.0520, -0.0177, -0.0745],\n",
      "          [ 0.0365, -0.0562,  0.0769,  0.0651,  0.0295],\n",
      "          [-0.0026,  0.0669, -0.0531, -0.0057, -0.0145],\n",
      "          [ 0.0736,  0.0075, -0.0750, -0.0108,  0.0326]],\n",
      "\n",
      "         [[-0.0046, -0.0556, -0.0161, -0.0609,  0.0197],\n",
      "          [-0.0552,  0.0754,  0.0282, -0.0749, -0.0123],\n",
      "          [ 0.0188,  0.0179,  0.0761,  0.0003,  0.0219],\n",
      "          [ 0.0429,  0.0041, -0.0735, -0.0044, -0.0668],\n",
      "          [-0.0659,  0.0195, -0.0245, -0.0732,  0.0796]],\n",
      "\n",
      "         [[ 0.0233, -0.0455,  0.0500,  0.0241,  0.0329],\n",
      "          [-0.0258,  0.0071,  0.0360,  0.0058,  0.0307],\n",
      "          [ 0.0008,  0.0025, -0.0586, -0.0779, -0.0808],\n",
      "          [ 0.0444,  0.0306, -0.0363, -0.0582,  0.0705],\n",
      "          [-0.0508, -0.0550, -0.0354, -0.0354, -0.0618]]]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0041, -0.0420, -0.0594, -0.0558, -0.0583,  0.0512, -0.0127, -0.0285,\n",
      "        -0.0249, -0.0495,  0.0457, -0.0551, -0.0101, -0.0055,  0.0586,  0.0547],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0211,  0.0451,  0.0429,  ...,  0.0088,  0.0224, -0.0471],\n",
      "        [-0.0024, -0.0372, -0.0082,  ..., -0.0390, -0.0372,  0.0265],\n",
      "        [ 0.0397,  0.0275, -0.0434,  ..., -0.0490,  0.0455, -0.0269],\n",
      "        ...,\n",
      "        [ 0.0138, -0.0235, -0.0367,  ..., -0.0076,  0.0067, -0.0013],\n",
      "        [-0.0013, -0.0374,  0.0426,  ..., -0.0497, -0.0116, -0.0215],\n",
      "        [-0.0276, -0.0484, -0.0336,  ...,  0.0167, -0.0328, -0.0254]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0224, -0.0088,  0.0408, -0.0003, -0.0061,  0.0314,  0.0020,  0.0309,\n",
      "        -0.0094, -0.0376, -0.0026, -0.0391,  0.0054, -0.0184,  0.0203, -0.0268,\n",
      "         0.0493,  0.0247, -0.0138,  0.0155, -0.0023,  0.0391, -0.0004,  0.0324,\n",
      "         0.0153, -0.0196, -0.0391, -0.0414, -0.0410,  0.0461, -0.0334, -0.0263,\n",
      "        -0.0135,  0.0311,  0.0457, -0.0147, -0.0210,  0.0334,  0.0289, -0.0380,\n",
      "        -0.0075,  0.0488,  0.0482, -0.0016,  0.0175,  0.0168, -0.0372,  0.0488,\n",
      "        -0.0482,  0.0331,  0.0270, -0.0213, -0.0206,  0.0066,  0.0185,  0.0431,\n",
      "         0.0393, -0.0247, -0.0279,  0.0400,  0.0003,  0.0225,  0.0241,  0.0431,\n",
      "        -0.0060,  0.0497,  0.0194,  0.0171, -0.0376,  0.0194,  0.0134, -0.0214,\n",
      "        -0.0172,  0.0060,  0.0454,  0.0393,  0.0112, -0.0427,  0.0405, -0.0406,\n",
      "        -0.0237,  0.0474, -0.0120,  0.0259,  0.0019,  0.0131,  0.0499, -0.0308,\n",
      "         0.0326,  0.0493, -0.0102,  0.0388,  0.0464, -0.0460, -0.0319, -0.0373,\n",
      "        -0.0312,  0.0106,  0.0086, -0.0281,  0.0145,  0.0128,  0.0416,  0.0493,\n",
      "        -0.0024, -0.0443, -0.0080,  0.0026,  0.0499,  0.0079, -0.0408, -0.0036,\n",
      "         0.0339,  0.0197,  0.0140,  0.0144,  0.0030, -0.0350,  0.0253, -0.0435],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0451,  0.0033, -0.0168,  ...,  0.0275,  0.0395, -0.0728],\n",
      "        [-0.0194,  0.0367, -0.0139,  ...,  0.0090,  0.0603, -0.0673],\n",
      "        [-0.0837, -0.0281, -0.0895,  ..., -0.0440, -0.0506, -0.0635],\n",
      "        ...,\n",
      "        [ 0.0817,  0.0891,  0.0343,  ..., -0.0632,  0.0201,  0.0078],\n",
      "        [-0.0357,  0.0583,  0.0006,  ...,  0.0834, -0.0393, -0.0434],\n",
      "        [ 0.0335,  0.0695,  0.0743,  ..., -0.0015, -0.0238,  0.0658]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0726,  0.0236,  0.0277,  0.0157,  0.0073, -0.0027, -0.0058, -0.0836,\n",
      "        -0.0280,  0.0072, -0.0111,  0.0223,  0.0602,  0.0369, -0.0606, -0.0655,\n",
      "         0.0250,  0.0449,  0.0077,  0.0589, -0.0871, -0.0295,  0.0384,  0.0532,\n",
      "         0.0037,  0.0100,  0.0762, -0.0163, -0.0270,  0.0701, -0.0256, -0.0700,\n",
      "        -0.0497, -0.0398,  0.0734, -0.0738,  0.0555,  0.0879, -0.0559, -0.0171,\n",
      "        -0.0761,  0.0430,  0.0051,  0.0355, -0.0117, -0.0606, -0.0533,  0.0245,\n",
      "        -0.0401,  0.0623, -0.0639, -0.0691,  0.0106,  0.0846, -0.0772,  0.0734,\n",
      "         0.0233, -0.0871,  0.0738,  0.0398, -0.0548, -0.0074,  0.0044,  0.0339,\n",
      "         0.0649, -0.0612,  0.0321, -0.0528, -0.0650, -0.0867, -0.0738, -0.0313,\n",
      "         0.0305,  0.0343, -0.0859, -0.0742, -0.0487, -0.0738, -0.0138,  0.0814,\n",
      "         0.0595,  0.0290,  0.0757,  0.0332], requires_grad=True), Parameter containing:\n",
      "tensor([[ 7.4720e-02, -3.7033e-02,  2.2633e-02, -2.9299e-02, -1.0758e-01,\n",
      "         -2.7914e-02,  4.7147e-02,  7.2995e-02, -4.8316e-03,  7.5717e-02,\n",
      "         -7.0819e-02, -7.9253e-02, -6.5106e-02, -4.6372e-02, -8.8993e-02,\n",
      "         -5.0561e-02,  1.0293e-01, -9.1952e-02, -7.4889e-02,  1.0672e-01,\n",
      "          9.7340e-02, -9.0431e-03, -8.2683e-02, -1.3279e-02,  4.0218e-02,\n",
      "          6.9621e-02,  5.6931e-03,  3.8120e-02,  5.4711e-02, -9.8265e-02,\n",
      "         -9.3262e-02,  6.8390e-02, -4.1864e-02, -7.8223e-02,  1.3382e-02,\n",
      "         -9.2728e-02, -8.5571e-02, -5.2973e-02,  2.3448e-02, -8.4009e-02,\n",
      "         -7.3248e-02, -3.0389e-02,  5.5964e-02,  8.0747e-02,  3.2651e-02,\n",
      "          2.9763e-02, -1.8624e-03, -1.3813e-02,  6.1302e-02, -6.5827e-02,\n",
      "          8.4126e-02, -1.0317e-03, -9.2003e-02, -2.0072e-02, -2.8546e-02,\n",
      "         -7.0805e-02,  6.0797e-02,  1.7247e-02,  4.3110e-02,  8.9510e-02,\n",
      "          3.7064e-02, -7.4014e-02, -1.9345e-02, -2.7277e-02, -3.8252e-02,\n",
      "          2.0421e-03, -3.4840e-03,  1.0716e-01,  7.7242e-02, -1.5249e-02,\n",
      "         -5.3641e-02, -8.1099e-02, -8.5387e-04,  7.2462e-02,  4.5889e-02,\n",
      "         -7.0926e-02, -3.2190e-02,  9.0934e-02,  7.9474e-03, -5.7775e-02,\n",
      "         -8.1789e-03,  6.4241e-02, -9.7538e-02, -2.5627e-02],\n",
      "        [-1.4549e-02,  5.2102e-02, -1.1337e-03, -8.1549e-02, -2.5505e-03,\n",
      "         -6.5795e-02, -1.7330e-02, -6.2516e-02, -7.7104e-03, -7.1097e-02,\n",
      "         -1.0464e-01, -6.2839e-02,  9.7716e-02, -2.3219e-02,  7.6755e-02,\n",
      "          3.5310e-02,  2.0425e-02,  9.0725e-03,  9.8500e-02,  4.5446e-02,\n",
      "         -3.9252e-02, -6.2023e-02,  9.7251e-02, -6.9013e-02, -1.5567e-02,\n",
      "          8.6145e-02,  8.2318e-02,  4.3843e-02,  7.7765e-02, -8.6365e-02,\n",
      "          6.9624e-02, -9.7024e-02,  9.4644e-04, -2.8133e-02,  6.0594e-02,\n",
      "          2.3742e-02,  9.9796e-02,  7.8679e-02, -9.8366e-02,  1.1652e-02,\n",
      "         -5.9680e-02, -2.1609e-02,  9.5184e-02, -7.2161e-02,  1.0717e-01,\n",
      "          5.3506e-02,  2.0271e-02,  9.1706e-02,  3.5880e-02, -1.9401e-02,\n",
      "         -4.8859e-02,  1.8396e-02,  9.5203e-02, -6.8258e-04,  4.5174e-02,\n",
      "          6.5628e-03,  8.6640e-02, -3.1911e-02, -4.0295e-02,  1.5781e-02,\n",
      "         -3.6895e-02, -9.4620e-02,  2.1217e-02, -1.5945e-02, -7.8780e-02,\n",
      "          4.3569e-02, -4.1548e-02, -6.9448e-02,  1.0705e-01,  6.6787e-02,\n",
      "          7.6728e-04,  7.9195e-02, -9.8885e-02,  3.1223e-04, -8.9636e-02,\n",
      "         -9.5124e-02,  6.4726e-02,  8.7658e-03, -3.6001e-02, -7.0122e-02,\n",
      "          6.2130e-02,  8.3093e-02,  8.3288e-02, -6.9159e-02],\n",
      "        [-7.9710e-02, -3.5801e-02,  6.7938e-02,  7.3080e-02, -5.0058e-02,\n",
      "          1.1543e-02,  4.1598e-02, -7.6286e-03,  7.0434e-02,  8.0990e-02,\n",
      "         -2.4691e-02,  7.1684e-04,  4.6182e-02,  8.3176e-02, -5.7531e-02,\n",
      "         -3.3057e-03,  1.0549e-01, -1.2113e-02,  2.9086e-02,  6.2980e-02,\n",
      "          4.6810e-02, -7.9050e-02, -8.9019e-02,  8.2279e-03,  6.4043e-02,\n",
      "          5.4268e-02, -2.6228e-02,  4.3992e-02,  8.5442e-02, -6.1587e-02,\n",
      "          9.3659e-02,  9.3917e-03, -3.1266e-02, -8.3665e-02, -1.4004e-02,\n",
      "         -7.9533e-02,  2.7096e-03,  6.7891e-02,  9.4912e-02, -9.0466e-02,\n",
      "          6.4467e-02, -7.5963e-02, -1.0839e-01, -9.9411e-02, -2.4975e-02,\n",
      "         -4.9072e-02,  4.3720e-02,  8.0527e-02,  7.7784e-02, -6.1469e-02,\n",
      "          5.1632e-02, -5.1375e-02,  8.2747e-02, -8.5183e-02, -1.0800e-02,\n",
      "          5.6677e-03,  8.6281e-02, -4.0913e-02, -1.8388e-02,  5.4532e-02,\n",
      "         -6.9409e-02,  1.2380e-02,  6.4196e-02, -8.0276e-02, -1.0526e-01,\n",
      "         -9.7513e-03,  9.2154e-02,  1.2138e-02,  9.9400e-02, -4.1978e-02,\n",
      "          2.5680e-02,  3.7875e-02,  2.9678e-02,  2.2604e-02,  5.1709e-02,\n",
      "         -7.5667e-02,  6.0539e-02,  8.9453e-02, -2.1957e-02, -5.7336e-02,\n",
      "         -6.1274e-02,  3.5350e-02, -2.7993e-03, -1.0227e-02],\n",
      "        [-5.7521e-02,  3.7780e-02,  5.7465e-02,  9.5074e-02,  2.6052e-02,\n",
      "         -7.2467e-02, -8.4998e-02, -2.9587e-02,  5.5333e-02, -5.6177e-02,\n",
      "         -1.0782e-01,  7.0820e-02,  2.0659e-02, -2.1464e-02, -8.7438e-03,\n",
      "         -8.8216e-02, -7.3959e-02, -3.6233e-02,  1.0424e-02, -9.6752e-03,\n",
      "          9.9904e-04,  1.0215e-01,  8.7750e-02,  6.1417e-02,  9.8831e-02,\n",
      "         -1.8654e-02,  5.0125e-02,  2.8865e-02,  9.7246e-03,  6.6479e-02,\n",
      "         -2.1864e-02,  4.4177e-02, -5.7141e-02, -7.5625e-02,  3.7956e-02,\n",
      "         -9.0082e-02,  1.0530e-01, -1.0380e-01,  2.8339e-02, -7.5064e-02,\n",
      "          5.0751e-02, -3.6674e-02, -8.9824e-02, -9.7812e-02,  3.9368e-02,\n",
      "         -7.6743e-02,  1.5499e-02, -5.5409e-02,  4.1924e-02,  3.0124e-02,\n",
      "         -9.6230e-02,  9.5519e-02,  8.5761e-02, -4.2255e-02, -6.9183e-02,\n",
      "          5.0935e-02, -7.4924e-03, -5.4750e-02, -1.0624e-01,  3.7085e-02,\n",
      "         -4.6371e-02,  9.3553e-02,  4.6171e-02, -3.8510e-02, -8.6089e-02,\n",
      "          3.8249e-02,  1.0022e-01, -5.9269e-02,  8.5081e-02,  8.2670e-02,\n",
      "          6.3686e-03,  1.1779e-02,  5.0708e-02, -2.2891e-02, -2.3350e-02,\n",
      "         -6.1899e-02, -3.7450e-02, -9.1134e-02,  5.3906e-02, -9.9758e-02,\n",
      "          9.2832e-02,  2.7688e-02,  2.3832e-02, -8.9695e-02],\n",
      "        [ 6.1642e-02,  8.2211e-02,  6.9851e-02,  7.2717e-02, -1.6326e-02,\n",
      "          4.4545e-02,  4.0618e-03, -8.1189e-02,  5.0367e-02,  1.9363e-03,\n",
      "         -1.0209e-02,  4.8755e-02,  4.3262e-02,  4.1371e-02,  1.0356e-01,\n",
      "          2.2297e-03,  1.2647e-02, -1.0889e-01, -5.6469e-02,  4.5430e-02,\n",
      "          6.9682e-02, -1.7475e-02, -2.9683e-02, -4.3041e-02, -6.3735e-02,\n",
      "         -5.4411e-02, -3.4971e-02, -1.8062e-02,  3.8721e-02, -3.2977e-02,\n",
      "          4.8163e-02, -6.8062e-04, -5.1255e-02,  7.9132e-02, -9.2809e-02,\n",
      "         -6.7671e-03, -1.0796e-01,  6.5530e-02, -3.6414e-03,  8.2911e-02,\n",
      "         -7.9154e-02, -2.2465e-02, -1.4072e-02,  1.0437e-01,  3.1128e-02,\n",
      "         -2.3096e-02,  5.6320e-04,  4.5167e-02,  7.4621e-02, -9.8027e-02,\n",
      "         -1.0260e-01,  1.4313e-02, -1.0235e-01, -7.1411e-02,  4.1721e-02,\n",
      "         -9.9438e-02,  3.7134e-02, -4.4229e-02,  7.1494e-02, -9.7304e-02,\n",
      "          9.8107e-02,  3.2479e-02,  3.5770e-03,  3.8825e-02, -6.8291e-02,\n",
      "          3.5495e-02, -8.8137e-03,  1.0879e-01, -2.1536e-02, -3.6843e-02,\n",
      "          7.0258e-02,  5.6665e-02, -1.1403e-02,  7.6669e-02,  3.7969e-02,\n",
      "          2.8612e-02,  4.9165e-02, -1.0524e-01,  5.4730e-03,  3.0833e-02,\n",
      "         -1.3245e-02,  5.2142e-02, -6.5299e-03, -4.4060e-02],\n",
      "        [-5.6869e-02, -6.6815e-02,  3.4562e-02,  3.6916e-02,  4.6387e-02,\n",
      "         -8.0718e-02,  9.2109e-02,  9.3958e-02,  8.8796e-02,  9.1881e-02,\n",
      "         -1.0434e-01,  8.4799e-02, -6.4422e-02,  9.1804e-02,  8.8694e-02,\n",
      "          1.0313e-01,  9.4115e-02, -5.1282e-05, -3.6537e-02,  4.3115e-02,\n",
      "          1.9606e-02,  6.9149e-02, -6.6631e-02,  3.7151e-02,  9.5187e-02,\n",
      "          7.4449e-02, -8.7170e-02,  4.9753e-02, -7.6585e-02, -5.8126e-02,\n",
      "         -1.8760e-02,  2.1925e-03,  9.7564e-03,  4.6547e-02,  4.6081e-02,\n",
      "          7.2616e-02,  4.1418e-03,  3.9422e-02,  1.6325e-02, -3.6596e-03,\n",
      "         -2.0959e-02,  7.6747e-03, -7.4546e-02, -9.2743e-02,  7.5807e-02,\n",
      "         -9.6501e-02, -8.4082e-02, -3.3877e-02,  8.7079e-02, -4.0584e-02,\n",
      "          6.3590e-02,  4.3205e-02,  4.2239e-02, -1.8348e-02, -3.8567e-02,\n",
      "          7.3487e-02, -3.9219e-02, -6.2323e-02,  6.2064e-02,  1.1447e-02,\n",
      "          1.0048e-01, -1.0411e-01,  1.9118e-02,  8.8416e-02,  4.4900e-02,\n",
      "          1.5375e-02, -9.3696e-02,  5.4061e-02, -4.5905e-04,  3.9861e-02,\n",
      "          6.2528e-02, -6.8892e-02,  3.9077e-02, -7.5017e-02, -1.0355e-01,\n",
      "         -1.0865e-01,  2.4903e-02,  1.5949e-02,  2.9450e-02,  6.8438e-02,\n",
      "          6.8368e-02,  6.7252e-02, -7.4650e-02, -2.3829e-02],\n",
      "        [ 5.1404e-03,  8.4207e-02,  3.4422e-02, -4.6385e-02,  5.8555e-03,\n",
      "          5.8820e-02,  5.6667e-02, -3.8055e-02,  2.0718e-02,  9.8700e-02,\n",
      "         -1.5149e-03,  8.3251e-02, -1.4084e-02, -1.4745e-04,  7.7666e-02,\n",
      "          5.9247e-03,  6.5895e-02, -7.9155e-02, -1.1887e-02, -7.2679e-03,\n",
      "          1.7703e-02,  7.1677e-02,  4.4530e-03,  2.0044e-02,  1.0256e-01,\n",
      "         -9.5952e-02, -1.5581e-02, -1.0810e-01,  7.9578e-02,  8.4507e-02,\n",
      "          5.1437e-02, -5.9369e-02, -4.5587e-02, -6.4741e-02, -6.3556e-02,\n",
      "         -9.7947e-02, -7.3455e-02, -8.4877e-02, -4.0626e-03,  1.6358e-02,\n",
      "         -1.0784e-01,  2.7226e-02, -8.1692e-02, -2.5172e-02, -5.7949e-02,\n",
      "          1.0077e-02, -1.9369e-02,  1.0575e-01, -5.3631e-02, -1.0402e-01,\n",
      "          1.5561e-02, -7.6321e-02, -8.6879e-02,  2.8109e-02,  9.1220e-02,\n",
      "         -4.7382e-02,  5.7783e-02, -1.0300e-02,  3.0834e-03,  1.3440e-02,\n",
      "          1.6894e-02, -1.8733e-02, -1.0596e-01, -6.2994e-02,  1.8307e-02,\n",
      "          2.9066e-02, -9.9074e-02,  2.4371e-02, -6.0641e-02,  9.2893e-02,\n",
      "         -1.0410e-01,  5.6296e-02,  1.0071e-01, -7.9781e-02,  6.4888e-02,\n",
      "         -1.0642e-01, -9.5364e-02,  9.3078e-02, -9.9959e-02, -3.5422e-02,\n",
      "          8.2955e-03, -7.0175e-02, -1.0049e-01, -1.0797e-01],\n",
      "        [-4.5197e-02,  8.1863e-02,  4.9212e-02, -2.2833e-02,  5.8143e-02,\n",
      "          4.8780e-02, -9.6647e-02,  3.5909e-02,  1.3845e-02, -9.1007e-02,\n",
      "          1.3681e-03,  6.8653e-02, -2.8136e-02, -6.7421e-02,  6.9147e-02,\n",
      "         -1.0183e-01,  1.8471e-02,  9.6053e-02,  4.1409e-02,  4.0769e-02,\n",
      "          7.4624e-02, -1.3487e-02, -7.1444e-02,  5.2014e-02,  9.5487e-02,\n",
      "         -6.2059e-02, -5.3253e-02, -6.4883e-02, -3.3655e-02,  7.8179e-02,\n",
      "         -3.1083e-02, -7.1060e-02,  9.4749e-02,  1.9562e-02, -6.7829e-02,\n",
      "         -5.6692e-02, -8.4828e-02,  1.0615e-01,  6.6465e-03,  1.0751e-01,\n",
      "          4.8815e-02, -4.1209e-02,  3.5071e-02, -1.0376e-01, -1.0899e-01,\n",
      "          2.0449e-02, -4.9607e-02,  7.8818e-02, -6.0587e-02, -7.7848e-02,\n",
      "         -6.7112e-02,  7.2739e-02, -1.2088e-02, -8.2349e-02, -1.2278e-02,\n",
      "         -5.7669e-02, -7.8360e-02, -8.6286e-02, -8.1159e-02,  6.2614e-02,\n",
      "          9.5404e-02, -1.5866e-02, -4.2244e-02,  6.7349e-02,  2.7244e-02,\n",
      "         -9.6502e-02,  5.8960e-02,  7.2947e-03,  5.0542e-02,  7.0418e-02,\n",
      "          2.1225e-02,  6.9799e-02,  9.8481e-02, -2.1660e-03, -7.5675e-02,\n",
      "          7.3422e-02, -6.3018e-03,  8.4734e-03,  1.0534e-01, -8.1016e-02,\n",
      "         -5.8918e-02,  1.4863e-02,  1.7277e-02, -2.9098e-02],\n",
      "        [ 3.4486e-02, -4.1528e-03,  3.5370e-02,  3.6569e-03,  1.8759e-02,\n",
      "          1.4966e-03, -6.9203e-03,  7.1333e-02, -6.0913e-02,  1.6937e-02,\n",
      "         -2.5126e-02, -2.4846e-02,  8.4782e-02, -1.1931e-02,  2.4115e-02,\n",
      "         -7.6902e-02, -5.7674e-03, -7.9801e-02, -3.4915e-02,  8.6521e-03,\n",
      "          7.8839e-02,  2.1683e-02,  2.0711e-02, -7.0089e-02, -5.4690e-03,\n",
      "          1.3485e-02,  1.0488e-01, -2.5735e-02, -7.5462e-02, -4.8351e-02,\n",
      "          3.8653e-02,  1.6589e-02, -8.2152e-03, -1.7785e-02, -3.2125e-02,\n",
      "          1.6347e-02,  6.1750e-02,  7.6255e-03,  7.1075e-02,  2.1785e-02,\n",
      "         -1.8315e-02,  2.4004e-02,  1.8707e-02,  3.0416e-02,  3.7111e-02,\n",
      "          3.0595e-03, -6.5458e-02, -7.8925e-02,  6.8038e-02,  5.4665e-03,\n",
      "          6.5113e-02,  9.9990e-03,  5.6117e-02, -9.3190e-02,  4.7809e-02,\n",
      "         -2.3626e-02, -2.5924e-02, -2.8561e-02, -5.4572e-02,  1.5976e-02,\n",
      "          5.9204e-02,  5.8306e-02, -2.2705e-02,  4.4963e-02,  5.5633e-02,\n",
      "         -2.1988e-02, -7.5781e-02,  1.0717e-01,  9.2012e-02,  2.9230e-02,\n",
      "         -5.3857e-02, -4.9761e-02, -7.2850e-02, -2.7426e-02,  8.0276e-02,\n",
      "         -6.9638e-02,  4.5150e-02, -2.4104e-02,  2.7785e-02, -9.8843e-02,\n",
      "         -4.7899e-02,  3.5485e-02,  5.8829e-02, -2.9853e-02],\n",
      "        [ 5.1873e-02,  4.0955e-03, -7.4645e-03, -6.8628e-02, -7.3693e-02,\n",
      "          5.4688e-02,  5.2427e-02,  1.0070e-01, -7.2571e-03, -3.8213e-02,\n",
      "          9.0921e-02, -3.8406e-02, -9.8820e-02, -9.5251e-02, -3.5257e-02,\n",
      "         -6.6759e-02,  9.8751e-02, -9.9734e-02,  1.0270e-01, -1.0168e-01,\n",
      "          2.9182e-02,  9.3409e-02, -8.3186e-02,  8.8395e-04,  6.0486e-02,\n",
      "         -6.8292e-02,  6.1625e-02, -3.4016e-03, -8.3230e-03, -2.9651e-02,\n",
      "         -9.3716e-03,  2.5829e-02,  8.2675e-02,  6.5300e-02, -3.2988e-02,\n",
      "          1.0607e-01,  4.4119e-02, -4.3315e-03, -4.7141e-02, -1.0399e-01,\n",
      "         -3.7926e-02, -1.1549e-02,  3.5998e-03,  7.4740e-02,  7.9083e-02,\n",
      "         -2.9123e-02, -7.4828e-02, -3.2455e-02,  2.5300e-03,  3.1918e-02,\n",
      "          3.0496e-03, -9.5427e-02,  8.0078e-02,  5.5348e-03, -6.1480e-02,\n",
      "         -2.0523e-02, -6.6616e-02, -1.4122e-02,  8.0744e-02,  2.6810e-02,\n",
      "         -2.3411e-02,  8.7302e-02,  7.3676e-02, -5.6932e-02,  2.7330e-02,\n",
      "         -9.8354e-02,  7.9245e-02,  1.0182e-01,  9.4363e-02,  5.3450e-02,\n",
      "          3.4879e-02,  3.7789e-02,  2.0189e-02, -1.2903e-02,  4.1436e-02,\n",
      "         -4.8884e-03,  1.1998e-02, -7.5736e-02,  5.4112e-02,  2.7620e-03,\n",
      "          3.3790e-02, -7.2966e-02,  4.1594e-02, -9.9032e-02]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0406,  0.1021, -0.0540, -0.1031,  0.0069, -0.0503, -0.0761, -0.0980,\n",
      "        -0.0642,  0.0673], requires_grad=True)]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(params)\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.named_parameters at 0x000001D525AD0510>\n"
     ]
    }
   ],
   "source": [
    "print(list(net.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight : torch.Size([6, 1, 5, 5])\n",
      "conv1.bias : torch.Size([6])\n",
      "conv2.weight : torch.Size([16, 6, 5, 5])\n",
      "conv2.bias : torch.Size([16])\n",
      "fc1.weight : torch.Size([120, 400])\n",
      "fc1.bias : torch.Size([120])\n",
      "fc2.weight : torch.Size([84, 120])\n",
      "fc2.bias : torch.Size([84])\n",
      "fc3.weight : torch.Size([10, 84])\n",
      "fc3.bias : torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name,parameters in net.named_parameters():\n",
    "    print(name,':',parameters.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward函数的输入和输出都是Tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = t.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad() # 所有参数的梯度清零\n",
    "out.backward(t.ones(1,10)) # 反向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是，torch.nn只支持mini-batches，不支持一次只输入一个样本，即一次必须是一个batch。但如果只想输入一个样本，则用 `input.unsqueeze(0)`将batch_size设为１。例如 `nn.Conv2d` 输入必须是4维的，形如$nSamples \\times nChannels \\times Height \\times Width$。可将nSample设为1，即$1 \\times nChannels \\times Height \\times Width$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 损失函数\n",
    "\n",
    "nn实现了神经网络中大多数的损失函数，例如nn.MSELoss用来计算均方误差，nn.CrossEntropyLoss用来计算交叉熵损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward0 object at 0x000001D5257704F0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(28.9324, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = t.arange(0,10).view(1,10).float() \n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(output, target)\n",
    "print(loss.grad_fn)\n",
    "loss # loss是个scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果对loss进行反向传播溯源(使用`gradfn`属性)，可看到它的计算图如下：\n",
    "\n",
    "```\n",
    "input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d  \n",
    "      -> view -> linear -> relu -> linear -> relu -> linear \n",
    "      -> MSELoss\n",
    "      -> loss\n",
    "```\n",
    "\n",
    "当调用`loss.backward()`时，该图会动态生成并自动微分，也即会自动计算图中参数(Parameter)的导数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "反向传播之前 conv1.bias的梯度\n",
      "None\n",
      "反向传播之后 conv1.bias的梯度\n",
      "tensor([-0.0325,  0.1220, -0.0066, -0.0443,  0.0806, -0.0729])\n"
     ]
    }
   ],
   "source": [
    "# 运行.backward，观察调用之前和调用之后的grad\n",
    "net.zero_grad() # 把net中所有可学习参数的梯度清零\n",
    "print('反向传播之前 conv1.bias的梯度')\n",
    "print(net.conv1.bias.grad)\n",
    "loss.backward()\n",
    "print('反向传播之后 conv1.bias的梯度')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在反向传播计算完所有参数的梯度后，还需要使用优化方法来更新网络的权重和参数，例如随机梯度下降法(SGD)的更新策略如下：\n",
    "```\n",
    "weight = weight - learning_rate * gradient\n",
    "```\n",
    "\n",
    "手动实现如下：\n",
    "\n",
    "```python\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)# inplace 减法\n",
    "```\n",
    "\n",
    "`torch.optim`中实现了深度学习中绝大多数的优化方法，例如RMSProp、Adam、SGD等，更便于使用，因此大多数时候并不需要手动写上述代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#新建一个优化器，指定要调整的参数和学习率\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
    "\n",
    "# 在训练过程中\n",
    "# 先梯度清零(与net.zero_grad()效果一样)\n",
    "optimizer.zero_grad() \n",
    "\n",
    "# 计算损失\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "\n",
    "#反向传播\n",
    "loss.backward()\n",
    "\n",
    "#更新参数\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "####  数据加载与预处理\n",
    "\n",
    "在深度学习中数据加载及预处理是非常复杂繁琐的，但PyTorch提供了一些可极大简化和加快数据处理流程的工具。同时，对于常用的数据集，PyTorch也提供了封装好的接口供用户快速调用，这些数据集主要保存在torchvison中。\n",
    "\n",
    "`torchvision`实现了常用的图像数据加载功能，例如Imagenet、CIFAR10、MNIST等，以及常用的数据转换操作，这极大地方便了数据加载，并且代码具有可重用性。\n",
    "\n",
    "\n",
    "### 小试牛刀：CIFAR-10分类\n",
    "\n",
    "下面我们来尝试实现对CIFAR-10数据集的分类，步骤如下: \n",
    "\n",
    "1. 使用torchvision加载并预处理CIFAR-10数据集\n",
    "2. 定义网络\n",
    "3. 定义损失函数和优化器\n",
    "4. 训练网络并更新网络参数\n",
    "5. 测试网络\n",
    "\n",
    "####   CIFAR-10数据加载及预处理\n",
    "\n",
    "CIFAR-10[^3]是一个常用的彩色图片数据集，它有10个类别: 'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'。每张图片都是$3\\times32\\times32$，也即3-通道彩色图片，分辨率为$32\\times32$。\n",
    "\n",
    "[^3]: http://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "show = ToPILImage() # 可以把Tensor转成Image，方便可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /home/cy/tmp/data/cifar-10-python.tar.gz\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 第一次运行程序torchvision会自动下载CIFAR-10数据集，\n",
    "# 大约100M，需花费一定的时间，\n",
    "# 如果已经下载有CIFAR-10，可通过root参数指定\n",
    "\n",
    "# 定义对数据的预处理\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(), # 转为Tensor\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # 归一化\n",
    "                             ])\n",
    "\n",
    "# 训练集\n",
    "trainset = tv.datasets.CIFAR10(\n",
    "                    root='/home/cy/tmp/data/', \n",
    "                    train=True, \n",
    "                    download=True,\n",
    "                    transform=transform)\n",
    "\n",
    "trainloader = t.utils.data.DataLoader(\n",
    "                    trainset, \n",
    "                    batch_size=4,\n",
    "                    shuffle=True, \n",
    "                    num_workers=2)\n",
    "\n",
    "# 测试集\n",
    "testset = tv.datasets.CIFAR10(\n",
    "                    '/home/cy/tmp/data/',\n",
    "                    train=False, \n",
    "                    download=True, \n",
    "                    transform=transform)\n",
    "\n",
    "testloader = t.utils.data.DataLoader(\n",
    "                    testset,\n",
    "                    batch_size=4, \n",
    "                    shuffle=False,\n",
    "                    num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset对象是一个数据集，可以按下标访问，返回形如(data, label)的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m (data, label) \u001b[39m=\u001b[39m trainset[\u001b[39m100\u001b[39m]\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(classes[label])\n\u001b[0;32m      4\u001b[0m \u001b[39m# (data + 1) / 2是为了还原被归一化的数据\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainset' is not defined"
     ]
    }
   ],
   "source": [
    "(data, label) = trainset[100]\n",
    "print(classes[label])\n",
    "\n",
    "# (data + 1) / 2是为了还原被归一化的数据\n",
    "show((data + 1) / 2).resize((100, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader是一个可迭代的对象，它将dataset返回的每一条数据拼接成一个batch，并提供多线程加速优化和数据打乱等操作。当程序对dataset的所有数据遍历完一遍之后，相应的对Dataloader也完成了一次迭代。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataiter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(trainloader)\n\u001b[0;32m      2\u001b[0m images, labels \u001b[39m=\u001b[39m dataiter\u001b[39m.\u001b[39mnext() \u001b[39m# 返回4张图片及标签\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m%11s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m%\u001b[39mclasses[labels[j]] \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.__next__() # 返回4张图片及标签\n",
    "print(' '.join('%11s'%classes[labels[j]] for j in range(4)))\n",
    "show(tv.utils.make_grid((images+1)/2)).resize((400,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####   定义网络\n",
    "\n",
    "拷贝上面的LeNet网络，修改self.conv1第一个参数为3通道，因CIFAR-10是3通道彩图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)  \n",
    "        self.fc1   = nn.Linear(16*5*5, 120)  \n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) \n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) \n",
    "        x = x.view(x.size()[0] -1) \n",
    "        x = F.relu(self.fc1(x)),\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)        \n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  定义损失函数和优化器(loss和optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "criterion = nn.CrossEntropyLoss() # 交叉熵损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   训练网络\n",
    "\n",
    "所有网络的训练流程都是类似的，不断地执行如下流程：\n",
    "\n",
    "- 输入数据\n",
    "- 前向传播+反向传播\n",
    "- 更新参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.157\n",
      "[1,  4000] loss: 1.815\n",
      "[1,  6000] loss: 1.676\n",
      "[1,  8000] loss: 1.599\n",
      "[1, 10000] loss: 1.557\n",
      "[1, 12000] loss: 1.466\n",
      "[2,  2000] loss: 1.410\n",
      "[2,  4000] loss: 1.381\n",
      "[2,  6000] loss: 1.331\n",
      "[2,  8000] loss: 1.312\n",
      "[2, 10000] loss: 1.281\n",
      "[2, 12000] loss: 1.249\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "t.set_num_threads(8)\n",
    "for epoch in range(2):  \n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        # 输入数据\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()   \n",
    "        \n",
    "        # 更新参数 \n",
    "        optimizer.step()\n",
    "        \n",
    "        # 打印log信息\n",
    "        # loss 是一个scalar,需要使用loss.item()来获取数值，不能使用loss[0]\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999: # 每2000个batch打印一下训练状态\n",
    "            print('[%d, %5d] loss: %.3f' \\\n",
    "                  % (epoch+1, i+1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处仅训练了2个epoch（遍历完一遍数据集称为一个epoch），来看看网络有没有效果。将测试图片输入到网络中，计算它的label，然后与实际的label进行比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "实际的label:       cat     ship     ship    plane\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=400x100 at 0x7F632C0DB110>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next() # 一个batch返回4张图片\n",
    "print('实际的label: ', ' '.join(\\\n",
    "            '%08s'%classes[labels[j]] for j in range(4)))\n",
    "show(tv.utils.make_grid(images / 2 - 0.5)).resize((400,100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着计算网络预测的label："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果:    dog  ship plane plane\n"
     ]
    }
   ],
   "source": [
    "# 计算图片在每个类别上的分数\n",
    "outputs = net(images)\n",
    "# 得分最高的那个类\n",
    "_, predicted = t.max(outputs.data, 1)\n",
    "\n",
    "print('预测结果: ', ' '.join('%5s'\\\n",
    "            % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "已经可以看出效果，准确率50%，但这只是一部分的图片，再来看看在整个测试集上的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000张测试集中的准确率为: 53 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0 # 预测正确的图片数\n",
    "total = 0 # 总共的图片数\n",
    "\n",
    "\n",
    "# 由于测试的时候不需要求导，可以暂时关闭autograd，提高速度，节约内存\n",
    "with t.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = t.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "print('10000张测试集中的准确率为: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练的准确率远比随机猜测(准确率10%)好，证明网络确实学到了东西。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  在GPU训练\n",
    "就像之前把Tensor从CPU转到GPU一样，模型也可以类似地从CPU转到GPU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9488, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = t.device(\"cuda:0\" if t.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net.to(device)\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "output = net(images)\n",
    "loss= criterion(output,labels)\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果发现在GPU上并没有比CPU提速很多，实际上是因为网络比较小，GPU没有完全发挥自己的真正实力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对PyTorch的基础介绍至此结束。总结一下，本节主要包含以下内容。\n",
    "\n",
    "1. Tensor: 类似Numpy数组的数据结构，与Numpy接口类似，可方便地互相转换。\n",
    "2. autograd/: 为tensor提供自动求导功能。\n",
    "3. nn: 专门为神经网络设计的接口，提供了很多有用的功能(神经网络层，损失函数，优化器等)。\n",
    "4. 神经网络训练: 以CIFAR-10分类为例演示了神经网络的训练流程，包括数据加载、网络搭建、训练及测试。\n",
    "\n",
    "通过本节的学习，相信读者可以体会出PyTorch具有接口简单、使用灵活等特点。从下一章开始，本书将深入系统地讲解PyTorch的各部分知识。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
